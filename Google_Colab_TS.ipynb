{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL2VrLjtHZCs"
      },
      "source": [
        "# Overview\n",
        "\n",
        "This Colab helps to create and validate a training set for the k-NN classifier described in the MediaPipe [Pose Classification](https://google.github.io/mediapipe/solutions/pose_classification.html) soultion and export to a CSV and then use it in the [ML Kit sample app](https://developers.google.com/ml-kit/vision/pose-detection/classifying-poses#4_integrate_with_the_ml_kit_quickstart_app)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8OxqytxxV-e"
      },
      "source": [
        "# Start Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGJFajURxZii"
      },
      "source": [
        "Connect the Colab to hosted Python3 runtime (check top-right corner) and then install required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsA8WJi60PaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880322b2-d1cd-4849-c99e-b49ad973dd9d"
      },
      "source": [
        "!pip install pillow\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install opencv-python\n",
        "!pip install tqdm\n",
        "!pip install requests"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "Z0eytaglAvm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf591c5-c9ad-481f-c0af-5c9e71447301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.9 sounddevice-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7S1Dl8Dhfa2"
      },
      "source": [
        "# Helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5Ay8WCLqosN"
      },
      "source": [
        "## Commons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swiAP0RYqqVM"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def show_image(img, figsize=(10, 10)):\n",
        "  \"\"\"Shows output PIL image.\"\"\"\n",
        "  plt.figure(figsize=figsize)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUbZ_c-Aq4B"
      },
      "source": [
        "## Bootstrap helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw2xYlGmAt3q"
      },
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "import tqdm\n",
        "\n",
        "import io\n",
        "from PIL import Image\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageDraw\n",
        "import requests\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from mediapipe.python.solutions import drawing_utils as mp_drawing\n",
        "from mediapipe.python.solutions import pose as mp_pose\n",
        "\n",
        "\n",
        "class BootstrapHelper(object):\n",
        "  \"\"\"Helps to bootstrap images and filter pose samples for classification.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               images_in_folder,\n",
        "               images_out_folder,\n",
        "               csvs_out_folder):\n",
        "    self._images_in_folder = images_in_folder\n",
        "    self._images_out_folder = images_out_folder\n",
        "    self._csvs_out_folder = csvs_out_folder\n",
        "\n",
        "    # Get list of pose classes and print image statistics.\n",
        "    self._pose_class_names = sorted([n for n in os.listdir(self._images_in_folder) if not n.startswith('.')])\n",
        "\n",
        "  def bootstrap(self, per_pose_class_limit=None):\n",
        "    \"\"\"Bootstraps images in a given folder.\n",
        "\n",
        "    Required image in folder (same use for image out folder):\n",
        "      pushups_up/\n",
        "        image_001.jpg\n",
        "        image_002.jpg\n",
        "        ...\n",
        "      pushups_down/\n",
        "        image_001.jpg\n",
        "        image_002.jpg\n",
        "        ...\n",
        "      ...\n",
        "\n",
        "    Produced CSVs out folder:\n",
        "      pushups_up.csv\n",
        "      pushups_down.csv\n",
        "\n",
        "    Produced CSV structure with pose 3D landmarks:\n",
        "      sample_00001,x1,y1,z1,x2,y2,z2,....\n",
        "      sample_00002,x1,y1,z1,x2,y2,z2,....\n",
        "    \"\"\"\n",
        "    # Create output folder for CVSs.\n",
        "    if not os.path.exists(self._csvs_out_folder):\n",
        "      os.makedirs(self._csvs_out_folder)\n",
        "\n",
        "    for pose_class_name in self._pose_class_names:\n",
        "      print('Bootstrapping ', pose_class_name, file=sys.stderr)\n",
        "\n",
        "      # Paths for the pose class.\n",
        "      images_in_folder = os.path.join(self._images_in_folder, pose_class_name)\n",
        "      images_out_folder = os.path.join(self._images_out_folder, pose_class_name)\n",
        "      csv_out_path = os.path.join(self._csvs_out_folder, pose_class_name + '.csv')\n",
        "      if not os.path.exists(images_out_folder):\n",
        "        os.makedirs(images_out_folder)\n",
        "\n",
        "      with open(csv_out_path, 'w') as csv_out_file:\n",
        "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "        # Get list of images.\n",
        "        image_names = sorted([n for n in os.listdir(images_in_folder) if not n.startswith('.')])\n",
        "        if per_pose_class_limit is not None:\n",
        "          image_names = image_names[:per_pose_class_limit]\n",
        "\n",
        "        # Bootstrap every image.\n",
        "        for image_name in tqdm.tqdm(image_names):\n",
        "          # Load image.\n",
        "          input_frame = cv2.imread(os.path.join(images_in_folder, image_name))\n",
        "          input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "          # Initialize fresh pose tracker and run it.\n",
        "          with mp_pose.Pose() as pose_tracker:\n",
        "            result = pose_tracker.process(image=input_frame)\n",
        "            pose_landmarks = result.pose_landmarks\n",
        "\n",
        "          # Save image with pose prediction (if pose was detected).\n",
        "          output_frame = input_frame.copy()\n",
        "          if pose_landmarks is not None:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                image=output_frame,\n",
        "                landmark_list=pose_landmarks,\n",
        "                connections=mp_pose.POSE_CONNECTIONS)\n",
        "          output_frame = cv2.cvtColor(output_frame, cv2.COLOR_RGB2BGR)\n",
        "          cv2.imwrite(os.path.join(images_out_folder, image_name), output_frame)\n",
        "\n",
        "          # Save landmarks if pose was detected.\n",
        "          if pose_landmarks is not None:\n",
        "            # Get landmarks.\n",
        "            frame_height, frame_width = output_frame.shape[0], output_frame.shape[1]\n",
        "            pose_landmarks = np.array(\n",
        "                [[lmk.x * frame_width, lmk.y * frame_height, lmk.z * frame_width]\n",
        "                 for lmk in pose_landmarks.landmark],\n",
        "                dtype=np.float32)\n",
        "            assert pose_landmarks.shape == (33, 3), 'Unexpected landmarks shape: {}'.format(pose_landmarks.shape)\n",
        "            csv_out_writer.writerow([image_name] + pose_landmarks.flatten().astype(np.str).tolist())\n",
        "\n",
        "          # Draw XZ projection and concatenate with the image.\n",
        "          projection_xz = self._draw_xz_projection(\n",
        "              output_frame=output_frame, pose_landmarks=pose_landmarks)\n",
        "          output_frame = np.concatenate((output_frame, projection_xz), axis=1)\n",
        "\n",
        "  def _draw_xz_projection(self, output_frame, pose_landmarks, r=0.5, color='red'):\n",
        "    frame_height, frame_width = output_frame.shape[0], output_frame.shape[1]\n",
        "    img = Image.new('RGB', (frame_width, frame_height), color='white')\n",
        "\n",
        "    if pose_landmarks is None:\n",
        "      return np.asarray(img)\n",
        "\n",
        "    # Scale radius according to the image width.\n",
        "    r *= frame_width * 0.01\n",
        "\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    for idx_1, idx_2 in mp_pose.POSE_CONNECTIONS:\n",
        "      # Flip Z and move hips center to the center of the image.\n",
        "      x1, y1, z1 = pose_landmarks[idx_1] * [1, 1, -1] + [0, 0, frame_height * 0.5]\n",
        "      x2, y2, z2 = pose_landmarks[idx_2] * [1, 1, -1] + [0, 0, frame_height * 0.5]\n",
        "\n",
        "      draw.ellipse([x1 - r, z1 - r, x1 + r, z1 + r], fill=color)\n",
        "      draw.ellipse([x2 - r, z2 - r, x2 + r, z2 + r], fill=color)\n",
        "      draw.line([x1, z1, x2, z2], width=int(r), fill=color)\n",
        "\n",
        "    return np.asarray(img)\n",
        "\n",
        "  def align_images_and_csvs(self, print_removed_items=False):\n",
        "    \"\"\"Makes sure that image folders and CSVs have the same sample.\n",
        "\n",
        "    Leaves only intersetion of samples in both image folders and CSVs.\n",
        "    \"\"\"\n",
        "    for pose_class_name in self._pose_class_names:\n",
        "      # Paths for the pose class.\n",
        "      images_out_folder = os.path.join(self._images_out_folder, pose_class_name)\n",
        "      csv_out_path = os.path.join(self._csvs_out_folder, pose_class_name + '.csv')\n",
        "\n",
        "      # Read CSV into memory.\n",
        "      rows = []\n",
        "      with open(csv_out_path) as csv_out_file:\n",
        "        csv_out_reader = csv.reader(csv_out_file, delimiter=',')\n",
        "        for row in csv_out_reader:\n",
        "          rows.append(row)\n",
        "\n",
        "      # Image names left in CSV.\n",
        "      image_names_in_csv = []\n",
        "\n",
        "      # Re-write the CSV removing lines without corresponding images.\n",
        "      with open(csv_out_path, 'w') as csv_out_file:\n",
        "        csv_out_writer = csv.writer(csv_out_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "        for row in rows:\n",
        "          image_name = row[0]\n",
        "          image_path = os.path.join(images_out_folder, image_name)\n",
        "          if os.path.exists(image_path):\n",
        "            image_names_in_csv.append(image_name)\n",
        "            csv_out_writer.writerow(row)\n",
        "          elif print_removed_items:\n",
        "            print('Removed image from CSV: ', image_path)\n",
        "\n",
        "      # Remove images without corresponding line in CSV.\n",
        "      for image_name in os.listdir(images_out_folder):\n",
        "        if image_name not in image_names_in_csv:\n",
        "          image_path = os.path.join(images_out_folder, image_name)\n",
        "          os.remove(image_path)\n",
        "          if print_removed_items:\n",
        "            print('Removed image from folder: ', image_path)\n",
        "\n",
        "  def analyze_outliers(self, outliers):\n",
        "    \"\"\"Classifies each sample agains all other to find outliers.\n",
        "\n",
        "    If sample is classified differrrently than the original class - it sould\n",
        "    either be deleted or more similar samples should be aadded.\n",
        "    \"\"\"\n",
        "    for outlier in outliers:\n",
        "      image_path = os.path.join(self._images_out_folder, outlier.sample.class_name, outlier.sample.name)\n",
        "\n",
        "      print('Outlier')\n",
        "      print('  sample path =    ', image_path)\n",
        "      print('  sample class =   ', outlier.sample.class_name)\n",
        "      print('  detected class = ', outlier.detected_class)\n",
        "      print('  all classes =    ', outlier.all_classes)\n",
        "\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      show_image(img, figsize=(20, 20))\n",
        "\n",
        "  def remove_outliers(self, outliers):\n",
        "    \"\"\"Removes outliers from the image folders.\"\"\"\n",
        "    for outlier in outliers:\n",
        "      image_path = os.path.join(self._images_out_folder, outlier.sample.class_name, outlier.sample.name)\n",
        "      os.remove(image_path)\n",
        "\n",
        "  def print_images_in_statistics(self):\n",
        "    \"\"\"Prints statistics from the input image folder.\"\"\"\n",
        "    self._print_images_statistics(self._images_in_folder, self._pose_class_names)\n",
        "\n",
        "  def print_images_out_statistics(self):\n",
        "    \"\"\"Prints statistics from the output image folder.\"\"\"\n",
        "    self._print_images_statistics(self._images_out_folder, self._pose_class_names)\n",
        "\n",
        "  def _print_images_statistics(self, images_folder, pose_class_names):\n",
        "    print('Number of images per pose class:')\n",
        "    for pose_class_name in pose_class_names:\n",
        "      n_images = len([\n",
        "          n for n in os.listdir(os.path.join(images_folder, pose_class_name))\n",
        "          if not n.startswith('.')])\n",
        "      print('  {}: {}'.format(pose_class_name, n_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIiEj8Tx_x-q"
      },
      "source": [
        "# Create dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpRszzilECFz"
      },
      "source": [
        "## Upload image samples\n",
        "\n",
        "Locally create a folder named `fitness_poses_images_in` with image samples.\n",
        "\n",
        "Images should repesent terminal states of desired pose classes. I.e. if you want to classify push-up provide images for two classes: when person is up, and when person is down.\n",
        "\n",
        "There should be about a few hundred samples per class covering different camera angles, environment conditions, body shapes, and exercise variations to build a good classifier.\n",
        "\n",
        "Required structure of the images_in_folder:\n",
        "```\n",
        "fitness_poses_images_in/\n",
        "  pushups_up/\n",
        "    image_001.jpg\n",
        "    image_002.jpg\n",
        "    ...\n",
        "  pushups_down/\n",
        "    image_001.jpg\n",
        "    image_002.jpg\n",
        "    ...\n",
        "  ...\n",
        "```\n",
        "\n",
        "Zip the `fitness_poses_images_in` folder:\n",
        "```\n",
        "zip -r fitness_poses_images_in.zip fitness_poses_images_in\n",
        "```\n",
        "\n",
        "And run the code below to upload it to the Colab runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DErZEmKUEDK0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "7820db4f-d4a3-4f05-a9f5-ca34a3df0fa1"
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "os.listdir('.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bd2e5db6-20e0-4e92-b9f4-5e8361b9cdc0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bd2e5db6-20e0-4e92-b9f4-5e8361b9cdc0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fitness_poses_images_in.zip to fitness_poses_images_in.zip\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'fitness_poses_images_in.zip', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtTCrVF9EQZd"
      },
      "source": [
        "Unzip the archive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwMkvJ1EEQ6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b9a95d-361d-4340-8b73-8a072f3ca901"
      },
      "source": [
        "import zipfile\n",
        "import io\n",
        "\n",
        "zf = zipfile.ZipFile(io.BytesIO(uploaded['fitness_poses_images_in.zip']), \"r\")\n",
        "zf.extractall()\n",
        "os.listdir('.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config',\n",
              " 'fitness_poses_images_in',\n",
              " '__MACOSX',\n",
              " 'fitness_poses_images_in.zip',\n",
              " 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QBS_P_Y_2mg"
      },
      "source": [
        "## Bootstrap images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bERVPO8Ja6j7"
      },
      "source": [
        "# Required structure of the images_in_folder:\n",
        "#\n",
        "#   fitness_poses_images_in/\n",
        "#     pushups_up/\n",
        "#       image_001.jpg\n",
        "#       image_002.jpg\n",
        "#       ...\n",
        "#     pushups_down/\n",
        "#       image_001.jpg\n",
        "#       image_002.jpg\n",
        "#       ...\n",
        "#     ...\n",
        "bootstrap_images_in_folder = 'fitness_poses_images_in'\n",
        "\n",
        "# Output folders for bootstrapped images and CSVs.\n",
        "bootstrap_images_out_folder = 'fitness_poses_images_out'\n",
        "bootstrap_csvs_out_folder = 'fitness_poses_csvs_out'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVYsbbJbOW7W"
      },
      "source": [
        "# Initialize helper.\n",
        "bootstrap_helper = BootstrapHelper(\n",
        "    images_in_folder=bootstrap_images_in_folder,\n",
        "    images_out_folder=bootstrap_images_out_folder,\n",
        "    csvs_out_folder=bootstrap_csvs_out_folder,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e832H-X6b-v7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d579b093-15a4-4be1-cb6f-e3e926d4d22c"
      },
      "source": [
        "# Check how many pose classes and images for them are available.\n",
        "bootstrap_helper.print_images_in_statistics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images per pose class:\n",
            "  sium_end: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAWtcZSHcQHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6355bf92-0c2e-4a85-fc36-71ffce91f1e2"
      },
      "source": [
        "# Bootstrap all images.\n",
        "# Set limit to some small number for debug.\n",
        "bootstrap_helper.bootstrap(per_pose_class_limit=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Bootstrapping  sium_end\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]<ipython-input-4-d218176abc6a>:110: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  csv_out_writer.writerow([image_name] + pose_landmarks.flatten().astype(np.str).tolist())\n",
            "100%|██████████| 17/17 [00:07<00:00,  2.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRdqXeUScko9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aee1acc-f68d-458c-8412-280d73519389"
      },
      "source": [
        "# Check how many images were bootstrapped.\n",
        "bootstrap_helper.print_images_out_statistics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images per pose class:\n",
            "  sium_end: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTc3dlvFgg50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44717ee0-c16e-4466-e9f9-661646f3f78a"
      },
      "source": [
        "# After initial bootstrapping images without detected poses were still saved in\n",
        "# the folderd (but not in the CSVs) for debug purpose. Let's remove them.\n",
        "bootstrap_helper.align_images_and_csvs(print_removed_items=False)\n",
        "bootstrap_helper.print_images_out_statistics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images per pose class:\n",
            "  sium_end: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd0OSLWXMJFC"
      },
      "source": [
        "## Dump for the App\n",
        "\n",
        "Dump filtered poses to CSV and download it.\n",
        "\n",
        "Please check this [guide](https://developers.google.com/ml-kit/vision/pose-detection/classifying-poses#4_integrate_with_the_ml_kit_quickstart_app) on how to use this CSV in the ML Kit sample app."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2VfIiLPML8A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a3badfee-7b0f-4ae1-8ba9-c6a4cfe3995b"
      },
      "source": [
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def dump_for_the_app():\n",
        "  pose_samples_folder = 'fitness_poses_csvs_out'\n",
        "  pose_samples_csv_path = 'fitness_poses_csvs_out.csv'\n",
        "  file_extension = 'csv'\n",
        "  file_separator = ','\n",
        "\n",
        "  # Each file in the folder represents one pose class.\n",
        "  file_names = [name for name in os.listdir(pose_samples_folder) if name.endswith(file_extension)]\n",
        "\n",
        "  with open(pose_samples_csv_path, 'w') as csv_out:\n",
        "    csv_out_writer = csv.writer(csv_out, delimiter=file_separator, quoting=csv.QUOTE_MINIMAL)\n",
        "    for file_name in file_names:\n",
        "      # Use file name as pose class name.\n",
        "      class_name = file_name[:-(len(file_extension) + 1)]\n",
        "\n",
        "      # One file line: `sample_00001,x1,y1,x2,y2,....`.\n",
        "      with open(os.path.join(pose_samples_folder, file_name)) as csv_in:\n",
        "        csv_in_reader = csv.reader(csv_in, delimiter=file_separator)\n",
        "        for row in csv_in_reader:\n",
        "          row.insert(1, class_name)\n",
        "          csv_out_writer.writerow(row)\n",
        "\n",
        "  files.download(pose_samples_csv_path)\n",
        "\n",
        "\n",
        "dump_for_the_app()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2b41e1fc-4c33-4fdb-94ef-99dd9cc812cc\", \"fitness_poses_csvs_out.csv\", 15853)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}